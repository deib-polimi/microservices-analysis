{
    "gates": [
        "nginx"
    ],
    "num_gates": 1,
    "size": 44,
    "shared_dbs": false,
    "num_services": 0,
    "num_dbs": 0,
    "name": "Azure/AzureML-Containers",
    "dbs": [],
    "buses": [],
    "num_dockers": 10,
    "images": [
        "nvidia/cuda@sha256",
        "nvidia/cuda",
        "ubuntu"
    ],
    "monitors": [],
    "files": [],
    "structure": {
        "detected_dbs": {
            "services": [],
            "names": [],
            "num": 0,
            "shared_dbs": false
        },
        "services": [],
        "path": [],
        "num_services": 0
    },
    "servers": [],
    "num_discos": 0,
    "discos": [],
    "num_monitors": 0,
    "url": "git://github.com/Azure/AzureML-Containers.git",
    "langs": [
        "dockerfile",
        "bash"
    ],
    "num_langs": 2,
    "dockers": [
        {
            "gates": [],
            "keywords": [
                "miniconda",
                "apt",
                "get",
                "tmp",
                "opt"
            ],
            "discos": [],
            "path": "/base/lite/ubuntu16.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "ubuntu:16.04",
            "buses": [],
            "from": "ubuntu",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "mpi",
                "intel",
                "version",
                "miniconda",
                "tmp"
            ],
            "discos": [],
            "path": "/base/cpu/intelmpi2018.3-ubuntu16.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "ubuntu:16.04",
            "buses": [],
            "from": "ubuntu",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "openmpi",
                "miniconda",
                "tmp",
                "apt",
                "etc"
            ],
            "discos": [],
            "path": "/base/cpu/openmpi3.1.2-ubuntu16.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "ubuntu:16.04",
            "buses": [],
            "from": "ubuntu",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "openmpi",
                "miniconda",
                "tmp",
                "apt",
                "etc"
            ],
            "discos": [],
            "path": "/base/cpu/openmpi3.1.2-ubuntu18.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "ubuntu:18.04",
            "buses": [],
            "from": "ubuntu",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "openmpi",
                "miniconda",
                "tmp",
                "apt",
                "etc"
            ],
            "discos": [],
            "path": "/base/gpu/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04",
            "buses": [],
            "from": "nvidia/cuda",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "openmpi",
                "miniconda",
                "tmp",
                "apt",
                "etc"
            ],
            "discos": [],
            "path": "/base/gpu/openmpi3.1.2-cuda10.0-cudnn7-ubuntu16.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "nvidia/cuda@sha256:27f07b36cf5dbf9c148ade5795e53932c421c9526143afc83e4f9dc55fb618fd",
            "buses": [],
            "from": "nvidia/cuda@sha256",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "openmpi",
                "miniconda",
                "tmp",
                "apt",
                "etc"
            ],
            "discos": [],
            "path": "/base/gpu/openmpi3.1.2-cuda9.0-cudnn7-ubuntu16.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "nvidia/cuda@sha256:5b4a2ecdf7e7594e8f6fc41c0ed0e6a716bfb6ddc0e4852a3dde58eae4692d73",
            "buses": [],
            "from": "nvidia/cuda@sha256",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "mpi",
                "intel",
                "version",
                "miniconda",
                "tmp"
            ],
            "discos": [],
            "path": "/base/gpu/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "nvidia/cuda@sha256:27f07b36cf5dbf9c148ade5795e53932c421c9526143afc83e4f9dc55fb618fd",
            "buses": [],
            "from": "nvidia/cuda@sha256",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "mpi",
                "intel",
                "version",
                "miniconda",
                "tmp"
            ],
            "discos": [],
            "path": "/base/gpu/intelmpi2018.3-cuda9.0-cudnn7-ubuntu16.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "nvidia/cuda@sha256:5b4a2ecdf7e7594e8f6fc41c0ed0e6a716bfb6ddc0e4852a3dde58eae4692d73",
            "buses": [],
            "from": "nvidia/cuda@sha256",
            "monitors": []
        },
        {
            "gates": [
                "nginx"
            ],
            "keywords": [
                "openmpi",
                "miniconda",
                "tmp",
                "apt",
                "etc"
            ],
            "discos": [],
            "path": "/base/gpu/openmpi3.1.2-cuda10.0-cudnn7-ubuntu18.04/Dockerfile",
            "langs": [
                "bash"
            ],
            "cmd_keywords": [],
            "dbs": [],
            "servers": [],
            "cmd": "",
            "from_full": "nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04",
            "buses": [],
            "from": "nvidia/cuda",
            "monitors": []
        }
    ],
    "avg_size_service": 4.4,
    "languages": [
        "dockerfile"
    ],
    "num_buses": 0,
    "num_files": 11,
    "num_servers": 0
}